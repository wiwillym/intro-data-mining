{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial laboratorio 2.1 y 2.2: Clasificación\n",
    "\n",
    "Bárbara Poblete; Juglar Díaz, Mauricio Quezada, Hernán Sarmiento.\n",
    "\n",
    "**Abril 2019**\n",
    "\n",
    "\n",
    "## 1. Anaconda\n",
    "\n",
    "Para este laboratorio (sesiones 2.1 y 2.2) usaremos Python y algunas biblioteca para entrenar clasificadores. \n",
    "La forma más fácil de tener un ambiente de Python con todas las bibliotecas más comunes es instalar *Anaconda*.\n",
    "\n",
    "Para instalar *Anaconda*:\n",
    "- Descarga en el siguiente link la última versión de Python: https://www.python.org/downloads/\n",
    "- Descarga en el siguiente link la última versión de Anaconda para Python 3.7: https://www.anaconda.com/distribution/\n",
    "- Asegúrate de dejar en el PATH el directorio `bin` de anaconda. Puedes probar tu instalación ejecutando `python` en un terminal y verificar que diga algo como `Python 3.7.3 |Anaconda 4.4.0` al principio.\n",
    "\n",
    "**Nota:** Anaconda facilita mucho la instalación de las bibliotecas que usaremos en este laboratorio. Instalar las bibliotecas (`scikit-learn`, `jupyter`) desde cero puede ser un poco complicado si no estás seguro/a de lo que estás haciendo. Por lo tanto, instalar Anaconda es altamente recomendado para estas sesiones de laboratorio.\n",
    "\n",
    "\n",
    "## 2. Jupyter\n",
    "\n",
    "**Jupyter notebook** es una aplicación Web que permite crear documentos con código Python, similar a los R Notebooks o R Markdown. De hecho los enunciados del laboratorio 1.1 y 1.2 lo hicimos en R Markdown.\n",
    "Para los laboratorios 2.1 y 2.2 usaremos un **notebook** donde deberás completar sus respuestas en el mismo archivo, y además, podrás verificar sus respuestas de inmediato. \n",
    "\n",
    "De hecho, para practicar puedes descargar este mismo notebook. Para ello anda a **u-cursos** y en **Material Docente/Laboratorio** descarga tutorial2.ipynb.\n",
    "Luego, para cargarlo en tu computador debes ir al directorio donde dejaste el archivo anterior y ejecutar **jupyter notebook** en la terminal de su computador. \n",
    "\n",
    "Por ejemplo, si descargaste **tutorial2.ipynb** en el directorio **tutoriales/**, entonces puedes cargarlo usando:\n",
    "\n",
    "```cd tutoriales/\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "Luego selecciona el archivo .ipynb y podrás comenzar a editar el notebook. \n",
    "\n",
    "**TIP: con Shift-Enter puedes ejecutar cada bloque del notebook.**\n",
    "\n",
    "\n",
    "## 3. Scikit-learn\n",
    "\n",
    "Hay muchas bibliotecas para hacer análisis de datos. \n",
    "Para este laboratorio (y probablemente para los siguientes), vamos a usar `scikit-learn` (http://scikit-learn.org) que contiene muchos modelos de machine learning ya instalados. \n",
    "\n",
    "**OJO**: Si ya instalaste *Anaconda*, no necesitas instalar nada dado que viene en el pack.\n",
    "\n",
    "Para el resto del tutorial, asumiremos que estás usando este mismo notebook. \n",
    "\n",
    "Para cargar las bibliotecas, haz click en el siguiente bloque de código, y ejecútalo presionando `Shift+Enter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si se muestra esto es porque ya está instalado!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "print(\"Si se muestra esto es porque ya está instalado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Ejemplo: Iris Dataset\n",
    "\n",
    "Vamos a usar un dataset muy usado y que aparece en muchos sitios web. El dataset se llama **iris**, y corresponde a un conjunto de datos que contiene 3 clases  El método **load_iris** permite cargar el Iris dataset, que contiene 150 **instancias** (filas) de 3 **clases** diferentes de flores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "y:\n",
      " [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = iris.data      ## datos, caracteristicas o features de cada flor. \n",
    "y = iris.target    ## clase para cada instancia anterior.\n",
    "\n",
    "print(\"X:\\n\", X[:10])   # muestra las primeras 10 filas que corresponden a las caracteristicas de 10 flores. \n",
    "print(\"y:\\n\", y[:10])   # muestra las primeras 10 clases para cada una de las instancias de X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos saber los nombres de los *features* (columnas) usando el campo **feature_names**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber cuáles son las clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "print(iris.target[1:150])  # mostramos las todas las clases de X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 Corresponde a setosa \n",
    "\n",
    "1 Corresponde a versicolor\n",
    "\n",
    "2 Corresponde a virginica\n",
    "\n",
    "Podemos verificar esto haciendo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris.target_names)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, lo que tenemos es la descripción de una flor (medidas) en una fila acompañada con la clase. \n",
    "\n",
    "Por ejemplo, para la segunda fila, tenemos:\n",
    "\n",
    "**4.9,  3. ,  1.4,  0.2**  y la clase asociada es **0 (setosa)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obtener una descripción más completa usando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que haremos a continuación será entrenar un clasificador y predecir con nuevos datos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Nuestro primer clasificador\n",
    "\n",
    "Entrenaremos nuestro primer clasificador con el *Iris dataset*. \n",
    "Para esto, usaremos un árbol de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X, y)   ## Entrenar usando X (features), y (clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el método **fit** entrenamos el clasificador con los datos de **X** y la clase asociada a cada uno, **y**. Para ver qué tan bien fue el entrenamiento, podemos evaluar el clasificador ejecutándolo sobre instancias y verificando que la clase sea la correcta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ya hemos entrenado nuestro clasificador empleando **fit**. Luego para predecir, usamos **predict**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X)   ## predecir la matriz X, los resultados (clases predecidas) quedan en y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, si ejecutáramos ```clf.predict([[1.0, 2.0, 3.0, 1.0 ... etc]])```, le estamos pasando al clasificador un dato con valores **[1.0, 2.0, 3.0, 1.0 ... etc]**. Al ejecutar **predict**, éste nos retornará un arreglo con el valor **0**, indicando que esos datos fueron clasificados como la clase **0**.\n",
    "\n",
    "En **scikit-learn** existe el método **accuracy_score** que computa el Accuracy de la clasificación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, tuvimos un accuracy del 100% con el clasificador (1.0). Sin embargo, **hicimos algo incorrecto**: evaluamos el clasificador con los mismos datos con los cuales lo entrenamos! \n",
    "\n",
    "Al hacer esto, lo que terminamos haciendo fue *aprender de los datos de entrada* y evaluamos (o testeamos) usando los mismos datos. Esto también se denomina **overfitting**. \n",
    "\n",
    "También podríamos ver otras métricas como precision, recall y f-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00        50\n",
      "           2       1.00      1.00      1.00        50\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde luego, la clasificación es perfecta. Para tener un resultado más realista de la clasificación vamos a dividir el dataset en dos: en **training set** y en un **test set**.\n",
    "\n",
    "El **training_set** nos permite aprender de ejemplos y ajustar el clasificador de acuerdo a éstos. \n",
    "El **test_set** nos permitirá comprender qué tan bien **generalizamos** con el clasificador con nuevos datos. \n",
    "\n",
    " En **scikit-learn** existe un método llamado **train_test_split**, que nos permite hacer esta separación de manera aleatoria y estratificada (es decir, manteniendo la proporción de clases entre las instancias de cada set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=37, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método nos retorna cuatro listas, los correspondientes a train y a test. Es decir, para el entrenamiento se usará **X_train** que tiene los features de entreamiento e **y_train** que son las clases. Así mismo, para  probar con nuevos datos (testing), usaremos **X_test** como los features de entreda e **y_test** las clases. \n",
    "\n",
    "El parámetro **test_size** nos permite regular la fracción de los datos que irán a test; en este caso 33% del dataset completo. \n",
    "\n",
    "El parámetro **random_state** nos permite fijar la semilla para tener resultados consistentes (genera la misma partición de datos). Si ejecutamos el método varias veces con la misma semilla, nos mostrará los mismos resultados siempre. \n",
    "\n",
    "El parámetro **stratify** recibe un arreglo con la distribución de clases, y el método intenta mantener esa misma distribución en las listas resultantes. Si no hicieramos esto, podríamos, por ejemplo, tener muchos datos de una clase en el set de entrenamiento. \n",
    "\n",
    "Ahora, al fin, podemos probar nuestro clasificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)    ## Entrenamos con X_train y clases y_train\n",
    "\n",
    "y_pred = clf.predict(X_test)   ## Predecimos con nuevos datos (los de test X_test)\n",
    "print(\"Accuracy en test set:\", accuracy_score(y_test, y_pred))   ## Evaluamos la predicción con lo que debería dar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios Finales\n",
    "\n",
    "* Observe detenidamente el código anterior para entender qué estamos haciendo.\n",
    "\n",
    "* Llegue al laboratorio preparado con los conceptos de **Accuracy**, **Precision**, **Recall**, **F-score** y **cross validation**.\n",
    "\n",
    "* Descague este dataset que será usado en la sesión 2.2: https://users.dcc.uchile.cl/~hsarmien/mineria/datasets/unbalanced.csv  \n",
    "\n",
    "* Asegurese antes de la sesión que las siguientes bibliotecas ya están instaladas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si muestra este mensaje es porque la carga de las librerías anteriores está ok!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics, model_selection\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC  # support vector machine classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "print(\"Si muestra este mensaje es porque la carga de las librerías anteriores está ok!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
